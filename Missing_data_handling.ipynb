{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are many missing values and they can be taken from the internet. I can proceed in that direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netflix_movie_data = pd.read_csv('./Datasets/netflix_titles.csv', lineterminator = '\\n')\n",
    "df_prime_movie_data = pd.read_csv('./Datasets/amazon_prime_titles.csv', lineterminator = '\\n')\n",
    "df_disney_plus_movie_data = pd.read_csv('./Datasets/disney_plus_titles.csv', lineterminator = '\\n')\n",
    "df_hulu_movie_data = pd.read_csv('./Datasets/hulu_titles.csv', lineterminator = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show_id            0\n",
      "type               0\n",
      "title              0\n",
      "director        2634\n",
      "cast             825\n",
      "country          831\n",
      "date_added        10\n",
      "release_year       0\n",
      "rating             4\n",
      "duration           3\n",
      "listed_in          0\n",
      "description        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_value_netflix = df_netflix_movie_data.isna().sum()\n",
    "print(missing_value_netflix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show_id            0\n",
      "type               0\n",
      "title              0\n",
      "director        2083\n",
      "cast            1233\n",
      "country         8996\n",
      "date_added      9513\n",
      "release_year       0\n",
      "rating           337\n",
      "duration           0\n",
      "listed_in          0\n",
      "description        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_value_prime = df_prime_movie_data.isna().sum()\n",
    "print(missing_value_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show_id           0\n",
      "type              0\n",
      "title             0\n",
      "director        473\n",
      "cast            190\n",
      "country         219\n",
      "date_added        3\n",
      "release_year      0\n",
      "rating            3\n",
      "duration          0\n",
      "listed_in         0\n",
      "description       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_value_disney_plus = df_disney_plus_movie_data.isna().sum()\n",
    "print(missing_value_disney_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show_id            0\n",
      "type               0\n",
      "title              0\n",
      "director        3070\n",
      "cast            3073\n",
      "country         1453\n",
      "date_added        28\n",
      "release_year       0\n",
      "rating           520\n",
      "duration         479\n",
      "listed_in          0\n",
      "description        4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_value_hulu = df_hulu_movie_data.isna().sum()\n",
    "print(missing_value_hulu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see clearly, above only columns director, cast, country, date_added, rating, duration. Rather than deleting them. If we can get those values back in the dataset it would be best.\n",
    "I can use information present on the website imdb to get the data and fill it. I can use web scrapping to get the data and fill it in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before that I can check data. One dataset row may have data of the for the other dataset missing row values. Let's first check for the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected Successfully!\n"
     ]
    }
   ],
   "source": [
    "conn = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",  # Use IP instead of 'localhost'\n",
    "    user=\"Himanshu\",\n",
    "    password=\"Hustling@2000\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
